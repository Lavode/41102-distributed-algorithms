Distributed algorithms

# Introduction

- Algorithms & concepts to allow for eg concurrent computing.

Leslie Lamport: A distributed system is a system, where a computer of which you
  did not know it exists, can prevent you from getting your work done.

# Defining dependable systems

- Fault -> Error -> Failure. Can chain, failure of one system being fault of
  another.
- Fault: Cause of the error. Internal to the system.
- Error: Internal, (externally unobservable) system state which does not
  conform to specification.
- Failure: Observable deviation of system from specification.

Example:
```
System      Fault           Error             Failure
Train       Tree on line    No train          Delay for passengers
Journey     Train delayed   Delay             Arrival 2h late
Exam        Arrival 2h late Missed time slot  Repeat exam
```

Possible faults:
- Timing
- Cables
- Power supply
- Messages lost
- Data loss
  - Protection in typical (single-host) scenarios: Redundancy, ie RAID
  - Distributed systems: Often unable to detect that something is corrupt
    (unlike single-host scenario)

## How to make systems tolerate faults

- Prevention: Software engineering topic
- Tolerance: Ensure individual fault does not cause failure
  - Replication / Redundancy
  - Recovery
- Removal: Detect presence of faults, remove faulty components
- Forecasting / prediction

- Safety != security. Safety is connected to loss of life / material due to
  accidents. Security is connected to malicious intent.

# Defining distributed computation

Just like the OSI model specifies a communication stack which offers and
consumes services to and of the layers, we aim to define a modular system.

- Processes `Pi := {p, q, r, s, ...} |Pi| = N`
- Each such process atop a communication stack (components / modules), able to
  exchange messages with each other
- Mostly talking about asynchronous protocols which don't make assumptions on
  the time (thereby not needing a shared clock, as expensive / error-prone)
- Each component can communicate async vertically (with modules in same
  process, via events)
- Notation:
  - Event for component `c`: `<c, event type | param1, param2, ...>`
  - Acting on events: `upon <c, ev_1 | param> do: ...`
  - Triggering events: `trigger <b, do_more | param>`
- Layered modules: Each module
    - Has an API to be used by layers above
    - Invokes the API of the layer below
    - Receives events from the layer below
    - Delivers events to the layers above
- Events four types:
  - Travel upwards (indication events) or downwards (requests / invocations)
  - Are inputs (entering the module) or outputs (leaving the module)

## Example: Module 'Jobhandler' jh

```
Events:
  Request: <jh, handle | job>
  Indication: <jh, confirm | job>

Properties:
  Every job submitted for handling is eventually confirmed.
```

Implementation of one such job handler (synchronous)
```
State:
  ...

upon <jh, handle | job> do
  "process job"
  trigger <jh, confirm | job>
```

Implementation of another such job handler (asynchronous)
```
State:
  buf := {} // Unbounded buffer, with implicit locks

upon <jh, handle | job> do
  buf << job
  trigger <jh, confirm | job>

upon buf != {} do:
  job := buf.pop
  "process job"
```

Depending on semantics of property, you might also want to not confirm until it
is actually done.
