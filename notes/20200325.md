# Byzantine distributed storage

Separate processes into replicas and clients. Clients run operations, replicas
only store and send out data. Replicas may have byzantine faults (arbitrary
returns, malicious intent), clients are assumed to be correct.

## (1, N) regular register

```
Inputs:
  <Read>
  <Write | v>

Out:
  <ReadReturn | v>
  <WriteReturn>

Properties:
  Termination: Every operation eventually terminates
  Validity:
    A read operation not concurrent with a write returns the value of the most
    recently completed operation.
    A concurrent read operation returns either the concurrently written value,
    or the most recently written value.
```

Idea: Writer (one of clients) signs and stores value and timestamp, signature
stored on replicas along timestamp and value. Readers (other clients) can then
validate the reads. Replicas need no keys present.

Simplified (non-event-based) notation:
```
init:
  (ts, val, sig) := nil
  wts := 0

op write(v):
  wts := wts + 1
  sigma := sign(WRITE || wts || v)
  send [WRITE, wts, v, sigma] to all proc
  // f max number of faulty processes
  wait for [ACK, ts'] such that ts' = wts
    from > (n+f)/2 processes

upon [WRITE, ts', v', sigma'] do:
  if ts' > ts:
    (ts, val, sigma) := (ts', v', sigma')
  send [ACK, ts'] to writer w

op read:
  // Read request identifier left out for brevity
  send [READ] to all proc
  wait for [VALUE, ts', v', sigma']
    from > (n+f) / 2 processes
    with verifysig(sigma', WRITE || ts' || v') = true // using pk of writer w.

  v := highest value by timestamp
  return v

upon [READ] do:
  ...
```

Difference to non-byzantine system model: Choice of quorum size.
- `n` processes
- At most `f` byzantine faulty processes

## Termination

Show: `n - f > (n + f) / 2`, if `n > 3f`. That is there are enough correct
processes around that a quorum can be formed.

- `n > 3f` assumption of system model

With `n = 3f + 1`:
```
n - f = 2f + 1 > (n + f) / 2 = (3f + f) / 2 = 2f
```

## Validity

Let Qw, Qr be quorums of writer and reader, = processes for which write-ack /
read-value received.

`min |Qw|, |Qr| > (n + f)/2` per register specification.

Show that there is at least one correct process in `Qw INTERSECT Qr`.
Suppose there wasn't. Count number of distinct correct processes in `Qw UNION Qr`.
Number is `>= |Qw| -f + |Qr| - f > (n + f)/2 - f + (n + f)/2 - f = n - f`

Conflict => Exists at least one correct process in intersection of quorums.

Another way to define byzantine quorums: The intersection of any two quorums
contains at least one correct process.

## Implementation without signatures

Would have to filter out values from faulty processes, but how to detect those?
Majority voting might not work (see last lecture, staggered correct vs constant
faulty processes).

Possible implementation: If there is a sufficiently large majority, return that
value. Otherwise, return value indicating that no sufficient majority
consensus, assuming `n > 4f` processes.

# Practical leaderless replication

List of uncoordinated storage nodes in 'cloud'. Clients reading and writing
data. Clients send requests directly to replicas.

Challenge: Real-life clients won't retry forever, unlike ideal ones in
abstraction. If a message is not delivered, it might never be delivered, rather
than at some point. Might lead to inconsistent state in storage system. Solutions:

- Anti-entropy: Auxiliary service within system will eliminate differences
- Read-repair: Clients, if an inconsistency is detected, will write the proper
  value back to the incosistent replicas

Allows, in practice, more than `f` failures temporarily.


Quorums for reading and writing. `r` replicas for reading, `w` replicas for writing.
So far: `r = w > n/2`.
  `r = 1, w = n` read-one, write-all
  `r = n, w = 1` read-all, write-one

`n = 5, r = 2, w = 4`
  - Tolerates 3 reader faults, 1 writer fault.

# KVS

- Name / value pairs. Allows to eg only write and read whole object, not in
  parts. (Unlike eg file system, where you can read/write end of file).

- Some systems use `r + w <= n`, with coordinator nodes.
  Eg: Each thing stored on `n = 3` nodes, but obviously total node of nodes not
  limited to 3.

- Semantics not formally specified. At most regular, certainly not atomic.
  No formal specification as eg multiple writers (where no agreed-upon
  definitions), with atomicicity especially being expensive and problematic
  (reader would have to write)

- Conflicts resolved using heuristic methods - not in agreement with formal
  semantics either.
  - Eg last-write wins => Might lead to data loss

- Practical systems usually have a notion of *eventual consistency*

- Some systems left clients merge conflicting values, as it is often easy for a
  specific application, but very difficult in general.
  Example: Shopping cart. Merge policy = combine different carts into one.

# DDIA chapter 5

- Leader-based replication (master-slave)
- Multi-leader replication
- Leaderless replication
